{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Machine Learning Landscape\n",
    "\n",
    "Machine Learning has been around for decades in some specialized applications such as *Optical Character Recognition (OCR).* But the first ML application that really became mainstream, was the *spam filter.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning\n",
    "\n",
    "Machine Learning is the science (and art) of programming computers so they can learn from data. A more engineering-oriented definition is: \n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. -Tom Mitchell, 1997\n",
    "\n",
    "## Why Use Machine Learning\n",
    "\n",
    "Machine Learning is great for:\n",
    "- Problems for which existing solutions require a lot of hand-tuning or long lists of rules: one Machine Learning algorithm can often simplify code and perform better.\n",
    "- Complex problems for which there is no good solution at all using a traditional approach: the best ML techniques can find a solution.\n",
    "- Fluctuating envrionments: a ML system can adapt to new data.\n",
    "- Getting insights about complex problems and large amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning Systems\n",
    "\n",
    "There are so many different types of ML systems that is useful to classify them in broad categories based on:\n",
    "- Whether or not they are trained with human supervision **(supervised, unsupervised, semisupervised, and Reinforcement Learning)**\n",
    "- Whether or not they can learn incrementally on the fly **(online versus batch learning)**\n",
    "- Whether they work by simply comparing new data points to known data points or instead detect patterns in the training data and build a predictive model, much like scientists do **(instance-based versus model-based learning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Supervised/Unsupervised Learning**\n",
    "\n",
    "#### **Supervised learning**\n",
    "\n",
    "The training data you feed to the algorithm includes the desired solutions, called *labels*. A typical supervised learning task is *classification.*\n",
    "e.g. the spam filter is trained with many example emails along with their class (spam or ham).\n",
    "\n",
    "Another typical task is to predict a target numeric value called *predictors.* This sort of task is called *regressions.* Note that some regression algorithms can be used for classification as well, and vice versa. For example, *Logistic Regression* is commonly used for classification, as it can output a value that corresponds to the probability of belonging to a given class.\n",
    "\n",
    "Some of the most importance supervised learning algorithms are:\n",
    "- k-Nearest Neighbors\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines (SVMs)\n",
    "- Decision Trees and Random Forests\n",
    "- Neural Networks (some)\n",
    "\n",
    "### **Unsupervised learning**\n",
    "\n",
    "The training data is *unlabeled.* The system tries to learn without a teacher. Some of the most important unsupervised learning algorithms include:\n",
    "- Clustering\n",
    "  - K-Means\n",
    "  - DBSCAN\n",
    "  - Hierarchical Cluster Analysis (HCA)\n",
    "- Anomaly detection and novelty detection\n",
    "  - One-class SVM\n",
    "  - Isolation Forest\n",
    "- Visualization and dimensionality reduction\n",
    "  - Principal Component Analysis (PCA)\n",
    "  - Kernel PCA\n",
    "  - Locally-Linear Embedding (LLE)\n",
    "  - t-distributed Stochastic Neighbor Embedding (t-SNE)\n",
    "- Association rule-learning\n",
    "  - Apriori\n",
    "  - Eclat\n",
    "\n",
    "A related task is *dimensionality reduction,* in which the goal is to simplify the data without losing too much information. One way is to merge several correlated features into one, this is called *feature extraction.*\n",
    "\n",
    "Yet another important unsupervised task is *anomaly detection.* The system is shown mostly normal instances during training, so it learns to recognize them and when it sees a new instance it can tell whether it looks like a normal one or whether it is likely an anomaly. A very similar task is *novelty detection:* the difference is that novelty detection algorithms expect to see only normal data during training, while anomally detection algorithms are usually more tolerant, they can often perform well even with a small percentage of outliers in the training set.\n",
    "\n",
    "Lastly, another common unsupervised task is *assocation rule learning,* in which the goal is to dig into large amounts of data and discover interesting relations between attributes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
